services:
  # ============================================
  # Caddy - Reverse Proxy with Auto-HTTPS
  # ============================================
  caddy:
    image: caddy:2-alpine
    container_name: medical-crm-caddy
    restart: unless-stopped
    ports:
      - "80:80" # HTTP
      - "443:443" # HTTPS
    networks:
      - web
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy-data:/data
      - caddy-config:/config
    environment:
      - TZ=Europe/Paris

  # ============================================
  # PostgreSQL Database
  # ============================================
  postgres:
    image: postgres:18-alpine
    container_name: medical-crm-postgres
    restart: unless-stopped
    networks:
      - backend
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres/init:/docker-entrypoint-initdb.d:ro
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-medical_crm}
      POSTGRES_USER: ${POSTGRES_USER:-medical_crm_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_INITDB_ARGS: "-E UTF8 --locale=fr_FR.UTF-8"
      TZ: Europe/Paris
      PGTZ: Europe/Paris
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "pg_isready -U ${POSTGRES_USER:-medical_crm_user} -d ${POSTGRES_DB:-medical_crm}",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 512M

  # ============================================
  # Backend API
  # ============================================
  backend:
    build:
      context: .
      dockerfile: ./packages/backend/Dockerfile
    container_name: medical-crm-backend
    restart: unless-stopped
    networks:
      - web
      - backend
    volumes:
      - backend-uploads:/app/packages/backend/uploads
      - backend-logs:/app/packages/backend/logs
      - backend-storage:/app/packages/backend/storage
    environment:
      NODE_ENV: production
      PORT: 3000

      # Database
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: ${POSTGRES_DB:-medical_crm}
      DB_USER: ${POSTGRES_USER:-medical_crm_user}
      DB_PASSWORD: ${POSTGRES_PASSWORD}

      # JWT
      JWT_SECRET: ${JWT_SECRET}
      JWT_EXPIRES_IN: ${JWT_EXPIRES_IN:-7d}
      JWT_REFRESH_SECRET: ${JWT_REFRESH_SECRET}
      JWT_REFRESH_EXPIRES_IN: ${JWT_REFRESH_EXPIRES_IN:-7d}

      # CORS
      CORS_ORIGIN: https://${FRONTEND_DOMAIN}

      # Email (optional)
      SMTP_HOST: ${SMTP_HOST}
      SMTP_PORT: ${SMTP_PORT:-587}
      SMTP_USER: ${SMTP_USER}
      SMTP_PASS: ${SMTP_PASS}
      SMTP_FROM: ${SMTP_FROM}

      # Admin user auto-creation
      ADMIN_EMAIL: ${ADMIN_EMAIL}
      ADMIN_PASSWORD: ${ADMIN_PASSWORD}
      ADMIN_FIRST_NAME: ${ADMIN_FIRST_NAME:-Admin}
      ADMIN_LAST_NAME: ${ADMIN_LAST_NAME:-User}

      # Other configs
      TZ: Europe/Paris
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test:
        [
          "CMD",
          "node",
          "-e",
          "require('http').get('http://localhost:3000/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 256M

  # ============================================
  # Frontend (Vue.js SPA)
  # ============================================
  frontend:
    build:
      context: .
      dockerfile: ./packages/frontend/Dockerfile
      args:
        VITE_API_URL: https://${BACKEND_DOMAIN}/api
    container_name: medical-crm-frontend
    restart: unless-stopped
    networks:
      - web
    environment:
      TZ: Europe/Paris
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 5s
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 32M

  # ============================================
  # PostgreSQL Backup to Cloudflare R2
  # ============================================
  postgres-backup:
    build:
      context: ./backup
      dockerfile: Dockerfile
    container_name: medical-crm-backup
    restart: unless-stopped
    dns:
      - 8.8.8.8
      - 1.1.1.1
    networks:
      - backend
    volumes:
      - ./backup/scripts:/scripts:ro
      - backup-temp:/backup
    environment:
      # Database
      POSTGRES_HOST: postgres
      POSTGRES_DB: ${POSTGRES_DB:-medical_crm}
      POSTGRES_USER: ${POSTGRES_USER:-medical_crm_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}

      # Cloudflare R2 (S3-compatible)
      AWS_ACCESS_KEY_ID: ${R2_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${R2_SECRET_ACCESS_KEY}
      AWS_ENDPOINT_URL: ${R2_ENDPOINT_URL}
      S3_BUCKET: ${R2_BUCKET_NAME}

      # Backup settings
      BACKUP_SCHEDULE: "0 0 * * *" # Daily at midnight
      BACKUP_RETENTION_DAYS: 30
      TZ: Europe/Paris
    depends_on:
      postgres:
        condition: service_healthy

# ============================================
# Networks
# ============================================
networks:
  web:
    name: medical-crm-web
    driver: bridge
  backend:
    name: medical-crm-backend
    driver: bridge
    internal: true # No external access

# ============================================
# Volumes
# ============================================
volumes:
  postgres_data:
    name: medical-crm-postgres-data
    driver: local
  caddy-data:
    name: medical-crm-caddy-data
    driver: local
  caddy-config:
    name: medical-crm-caddy-config
    driver: local
  backend-uploads:
    name: medical-crm-backend-uploads
    driver: local
  backend-logs:
    name: medical-crm-backend-logs
    driver: local
  backend-storage:
    name: medical-crm-backend-storage
    driver: local
  backup-temp:
    name: medical-crm-backup-temp
    driver: local
